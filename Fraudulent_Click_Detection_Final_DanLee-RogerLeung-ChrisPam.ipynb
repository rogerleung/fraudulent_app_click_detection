{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.0 |Anaconda custom (64-bit)| (default, Dec 23 2016, 11:57:41) [MSC v.1900 64 bit (AMD64)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dan\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\Dan\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)\n",
    "\n",
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# General libraries.\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier \n",
    "\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load datasets\n",
    "\n",
    "train = pd.read_csv('train.csv', nrows = 1000000)\n",
    "train_sample = pd.read_csv('train_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip</th>\n",
       "      <th>app</th>\n",
       "      <th>device</th>\n",
       "      <th>os</th>\n",
       "      <th>channel</th>\n",
       "      <th>click_time</th>\n",
       "      <th>attributed_time</th>\n",
       "      <th>is_attributed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87540</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>497</td>\n",
       "      <td>2017-11-07 09:30:38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105560</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>259</td>\n",
       "      <td>2017-11-07 13:40:27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101424</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>212</td>\n",
       "      <td>2017-11-07 18:05:24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94584</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>477</td>\n",
       "      <td>2017-11-07 04:58:08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68413</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>2017-11-09 09:00:09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ip  app  device  os  channel           click_time attributed_time  \\\n",
       "0   87540   12       1  13      497  2017-11-07 09:30:38             NaN   \n",
       "1  105560   25       1  17      259  2017-11-07 13:40:27             NaN   \n",
       "2  101424   12       1  19      212  2017-11-07 18:05:24             NaN   \n",
       "3   94584   13       1  13      477  2017-11-07 04:58:08             NaN   \n",
       "4   68413   12       1   1      178  2017-11-09 09:00:09             NaN   \n",
       "\n",
       "   is_attributed  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the data\n",
    "train_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip</th>\n",
       "      <th>app</th>\n",
       "      <th>device</th>\n",
       "      <th>os</th>\n",
       "      <th>channel</th>\n",
       "      <th>is_attributed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.00000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>91255.879670</td>\n",
       "      <td>12.04788</td>\n",
       "      <td>21.771250</td>\n",
       "      <td>22.818280</td>\n",
       "      <td>268.832460</td>\n",
       "      <td>0.002270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>69835.553661</td>\n",
       "      <td>14.94150</td>\n",
       "      <td>259.667767</td>\n",
       "      <td>55.943136</td>\n",
       "      <td>129.724248</td>\n",
       "      <td>0.047591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>40552.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>79827.000000</td>\n",
       "      <td>12.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>258.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>118252.000000</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>379.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>364757.000000</td>\n",
       "      <td>551.00000</td>\n",
       "      <td>3867.000000</td>\n",
       "      <td>866.000000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ip           app         device             os  \\\n",
       "count  100000.000000  100000.00000  100000.000000  100000.000000   \n",
       "mean    91255.879670      12.04788      21.771250      22.818280   \n",
       "std     69835.553661      14.94150     259.667767      55.943136   \n",
       "min         9.000000       1.00000       0.000000       0.000000   \n",
       "25%     40552.000000       3.00000       1.000000      13.000000   \n",
       "50%     79827.000000      12.00000       1.000000      18.000000   \n",
       "75%    118252.000000      15.00000       1.000000      19.000000   \n",
       "max    364757.000000     551.00000    3867.000000     866.000000   \n",
       "\n",
       "             channel  is_attributed  \n",
       "count  100000.000000  100000.000000  \n",
       "mean      268.832460       0.002270  \n",
       "std       129.724248       0.047591  \n",
       "min         3.000000       0.000000  \n",
       "25%       145.000000       0.000000  \n",
       "50%       258.000000       0.000000  \n",
       "75%       379.000000       0.000000  \n",
       "max       498.000000       1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# have a quick summary on the data\n",
    "train_sample.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# Check the types of the data\n",
    "\n",
    "print(type(train_sample['ip'][0]))\n",
    "print(type(train_sample['app'][0]))\n",
    "print(type(train_sample['device'][0]))\n",
    "print(type(train_sample['os'][0]))\n",
    "print(type(train_sample['channel'][0]))\n",
    "print(type(train_sample['is_attributed'][0]))\n",
    "print(type(train_sample['click_time'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create time attributes from the time stamp\n",
    "\n",
    "train_sample['click_time'] = pd.to_datetime(train_sample['click_time'])\n",
    "train_sample['click_date'] = train_sample['click_time'].dt.date\n",
    "train_sample['click_day'] = train_sample['click_time'].dt.weekday\n",
    "train_sample['click_hour'] = train_sample['click_time'].dt.hour\n",
    "train_sample['click_minute'] = train_sample['click_time'].dt.minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shuffle with random_state = 1\n",
    "train_sample = shuffle(train_sample, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# total clicks for ip address, more clicks are potentially a flag for fradulent click\n",
    "\n",
    "ip_counts = {}\n",
    "for click in train_sample['ip']:\n",
    "    if str(click) in ip_counts:\n",
    "        ip_counts[str(click)] += 1\n",
    "    else:\n",
    "        ip_counts[str(click)] = 1\n",
    "        click_count = []\n",
    "cur_ip = []\n",
    "i = 0\n",
    "for i in range(len(train_sample)):\n",
    "    cur_ip = train_sample['ip'][i]\n",
    "    click_count.append(ip_counts[str(cur_ip)])\n",
    "    i += 1\n",
    "train_sample['click_count'] = np.asarray(click_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34857\n",
      "34857\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'timedelta' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-f2ceb903fffc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mprior_clicks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclick_time_counts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclick\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mtrain_sample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'click_time'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain_sample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'click_time'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhours\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mprior_clicks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mi\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'timedelta' is not defined"
     ]
    }
   ],
   "source": [
    "# prior clicks in last hour, a high number of prior_clicks in the past hour is also a potential indicator of fraud\n",
    "\n",
    "click_time_counts = {}\n",
    "click_date = []\n",
    "# click_hour = []\n",
    "i = 0\n",
    "for click in train_sample['ip']:\n",
    "    if str(click) not in click_time_counts:\n",
    "        click_time_counts[str(click)] = {train_sample['click_time'][i]:1}\n",
    "    elif str(click) in click_time_counts and train_sample['click_time'][i] not in click_time_counts[str(click)]:\n",
    "        click_time_counts[str(click)][train_sample['click_time'][i]] = 1\n",
    "    elif str(click) in click_time_counts and train_sample['click_time'][i] in click_time_counts[str(click)]: \n",
    "        click_time_counts[str(click)][train_sample['click_time'][i]] += 1\n",
    "    i += 1\n",
    "    \n",
    "# print(click_time_counts)\n",
    "print(len(click_time_counts))\n",
    "print(len(train_sample['ip'].unique()))\n",
    "\n",
    "prior_clicks = []\n",
    "i = 0\n",
    "for click in train_sample['ip']:\n",
    "    prior_clicks.append(0)\n",
    "    for key in click_time_counts[str(click)]:\n",
    "        if key < train_sample['click_time'][i] and key > (train_sample['click_time'][i] - timedelta(hours = 1)):\n",
    "            prior_clicks[i] += 1\n",
    "    i += 1\n",
    "train_sample['prior_clicks'] = np.asarray(prior_clicks)\n",
    "print(train_sample.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip</th>\n",
       "      <th>app</th>\n",
       "      <th>device</th>\n",
       "      <th>os</th>\n",
       "      <th>channel</th>\n",
       "      <th>click_time</th>\n",
       "      <th>attributed_time</th>\n",
       "      <th>is_attributed</th>\n",
       "      <th>click_date</th>\n",
       "      <th>click_day</th>\n",
       "      <th>click_hour</th>\n",
       "      <th>click_minute</th>\n",
       "      <th>click_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43660</th>\n",
       "      <td>49293</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>178</td>\n",
       "      <td>2017-11-07 04:06:44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-11-07</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87278</th>\n",
       "      <td>123994</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>245</td>\n",
       "      <td>2017-11-07 14:04:21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-11-07</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14317</th>\n",
       "      <td>55920</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>442</td>\n",
       "      <td>2017-11-08 23:39:27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-11-08</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81932</th>\n",
       "      <td>62937</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>134</td>\n",
       "      <td>2017-11-08 00:53:46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-11-08</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95321</th>\n",
       "      <td>70361</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>412</td>\n",
       "      <td>2017-11-06 16:30:18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-11-06</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ip  app  device  os  channel          click_time attributed_time  \\\n",
       "43660   49293    1       1  19      178 2017-11-07 04:06:44             NaN   \n",
       "87278  123994   12       1  19      245 2017-11-07 14:04:21             NaN   \n",
       "14317   55920   14       1  13      442 2017-11-08 23:39:27             NaN   \n",
       "81932   62937    9       1  20      134 2017-11-08 00:53:46             NaN   \n",
       "95321   70361   15       1  13      412 2017-11-06 16:30:18             NaN   \n",
       "\n",
       "       is_attributed  click_date  click_day  click_hour  click_minute  \\\n",
       "43660              0  2017-11-07          1           4             6   \n",
       "87278              0  2017-11-07          1          14             4   \n",
       "14317              0  2017-11-08          2          23            39   \n",
       "81932              0  2017-11-08          2           0            53   \n",
       "95321              0  2017-11-06          0          16            30   \n",
       "\n",
       "       click_count  \n",
       "43660            8  \n",
       "87278          149  \n",
       "14317            2  \n",
       "81932            3  \n",
       "95321            4  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert the features into a single np array for faster processing\n",
    "\n",
    "ip = list(train_sample['ip'])\n",
    "app = list(train_sample['app'])\n",
    "device = list(train_sample['device'])\n",
    "os = list(train_sample['os'])\n",
    "channel = list(train_sample['channel'])\n",
    "click_day = list(train_sample['click_day'])\n",
    "click_count = list(train_sample['click_count'])\n",
    "\n",
    "\n",
    "X = []\n",
    "i = 0\n",
    "for x in range(100000):\n",
    "    # comment out the applicable\n",
    "    X.append([ip[i], app[i], device[i], os[i], channel[i], click_day[i], click_count[i]])\n",
    "    #X.append([ip[i], app[i], device[i], os[i], channel[i], click_hour[i]])\n",
    "    i += 1\n",
    "    \n",
    "Y = train_sample.is_attributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split into train and test.\n",
    "\n",
    "train_data, train_labels = X[:90000], Y[:90000]\n",
    "test_data, test_labels = X[90000:], Y[90000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training and classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (a decision tree): 0.9967\n",
      "Decision Tree Performance\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      9974\n",
      "          1       0.37      0.38      0.38        26\n",
      "\n",
      "avg / total       1.00      1.00      1.00     10000\n",
      "\n",
      "mean: 0.997 (std: 0.001)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DecisionTree\n",
    "\n",
    "dt = DecisionTreeClassifier(criterion=\"entropy\", splitter=\"best\", random_state=0)\n",
    "dt.fit(train_data, train_labels)\n",
    "\n",
    "print('Accuracy (a decision tree):', dt.score(test_data, test_labels))\n",
    "print(\"Decision Tree Performance\")\n",
    "print(classification_report(test_labels, dt.predict(test_data)))\n",
    "\n",
    "\n",
    "\n",
    "scores = cross_val_score(dt, train_data, train_labels, cv=10)\n",
    "print(\"mean: {:.3f} (std: {:.3f})\".format(scores.mean(),\n",
    "                                          scores.std()),\n",
    "                                          end=\"\\n\\n\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (a random forest): 0.9976\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      9974\n",
      "          1       0.60      0.23      0.33        26\n",
      "\n",
      "avg / total       1.00      1.00      1.00     10000\n",
      "\n",
      "Accuracy (adaboost with decision trees): 0.9974\n"
     ]
    }
   ],
   "source": [
    "#Ensemble Methods\n",
    "rfc = RandomForestClassifier(n_estimators=10, max_features=None)\n",
    "rfc.fit(train_data, train_labels)\n",
    "\n",
    "print('Accuracy (a random forest):', rfc.score(test_data, test_labels))\n",
    "print(classification_report(test_labels, rfc.predict(test_data)))\n",
    "\n",
    "abc = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1), n_estimators=100, learning_rate=0.1)\n",
    "abc.fit(train_data, train_labels)\n",
    "print('Accuracy (adaboost with decision trees):', abc.score(test_data, test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      9974\n",
      "          1       0.00      0.00      0.00        26\n",
      "\n",
      "avg / total       0.99      1.00      1.00     10000\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      9974\n",
      "          1       0.00      0.00      0.00        26\n",
      "\n",
      "avg / total       0.99      1.00      1.00     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# logstic and logsitcCV\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(train_data, train_labels)\n",
    "logreg.score(test_data, test_labels)\n",
    "print(classification_report(test_labels, logreg.predict(test_data)))\n",
    "\n",
    "\n",
    "logregCV = LogisticRegressionCV(cv =10) # 10-fold\n",
    "logregCV.fit(train_data, train_labels)\n",
    "logregCV.score(test_data, test_labels)\n",
    "print(classification_report(test_labels, logreg.predict(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering - Binarizing Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BINARIZING the device type\n",
    "\n",
    "train_sample_with_device_type_binarized = train_sample\n",
    "\n",
    "# Convert the features in to a single np array for faster processing\n",
    "\n",
    "ip = list(train_sample_with_device_type_binarized['ip'])\n",
    "app = list(train_sample_with_device_type_binarized['app'])\n",
    "device = list(train_sample_with_device_type_binarized['device'])\n",
    "os = list(train_sample_with_device_type_binarized['os'])\n",
    "channel = list(train_sample_with_device_type_binarized['channel'])\n",
    "click_day = list(train_sample_with_device_type_binarized['click_day'])\n",
    "click_count = list(train_sample_with_device_type_binarized['click_count'])\n",
    "\n",
    "# convert device to 1 or 0 - Recall in train_sample summary, \n",
    "# at least 75% of the device type is 1, probably are some budget phone which is likely to be a red flag\n",
    "\n",
    "for i in device:\n",
    "    if i == 1:\n",
    "        next\n",
    "    else:\n",
    "        i = 0\n",
    "\n",
    "\n",
    "X = []\n",
    "i = 0\n",
    "\n",
    "for x in range(100000):\n",
    "    # comment out the applicable\n",
    "    X.append([ip[i], app[i], device[i], os[i], channel[i], click_day[i], click_count[i]])\n",
    "    #X.append([ip[i], app[i], device[i], os[i], channel[i], click_hour[i]])\n",
    "    i += 1\n",
    "    \n",
    "    \n",
    "\n",
    "Y = train_sample.is_attributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split into train and test.\n",
    "\n",
    "train_data, train_labels = X[:90000], Y[:90000]\n",
    "test_data, test_labels = X[90000:], Y[90000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (a decision tree): 0.9967\n",
      "Decision Tree Performance\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      9974\n",
      "          1       0.37      0.38      0.38        26\n",
      "\n",
      "avg / total       1.00      1.00      1.00     10000\n",
      "\n",
      "mean: 0.997 (std: 0.001)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DecisionTree\n",
    "\n",
    "dt = DecisionTreeClassifier(criterion=\"entropy\", splitter=\"best\", random_state=0)\n",
    "dt.fit(train_data, train_labels)\n",
    "\n",
    "print('Accuracy (a decision tree):', dt.score(test_data, test_labels))\n",
    "print(\"Decision Tree Performance\")\n",
    "print(classification_report(test_labels, dt.predict(test_data)))\n",
    "\n",
    "\n",
    "\n",
    "scores = cross_val_score(dt, train_data, train_labels, cv=10)\n",
    "print(\"mean: {:.3f} (std: {:.3f})\".format(scores.mean(),\n",
    "                                          scores.std()),\n",
    "                                          end=\"\\n\\n\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (a random forest): 0.9975\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      9974\n",
      "          1       0.54      0.27      0.36        26\n",
      "\n",
      "avg / total       1.00      1.00      1.00     10000\n",
      "\n",
      "Accuracy (adaboost with decision trees): 0.9974\n"
     ]
    }
   ],
   "source": [
    "#Ensemble Methods\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=10, max_features=None)\n",
    "rfc.fit(train_data, train_labels)\n",
    "print('Accuracy (a random forest):', rfc.score(test_data, test_labels))\n",
    "print(classification_report(test_labels, rfc.predict(test_data)))\n",
    "\n",
    "abc = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1), n_estimators=100, learning_rate=0.1)\n",
    "abc.fit(train_data, train_labels)\n",
    "print('Accuracy (adaboost with decision trees):', abc.score(test_data, test_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Unnamed: 0     ip    app  device     os  channel  click_time  \\\n",
      "is_attributed                                                                 \n",
      "0                   49464  49464  49464   49464  49464    49464       49464   \n",
      "1                   49464  49464  49464   49464  49464    49464       49464   \n",
      "\n",
      "               attributed_time  \n",
      "is_attributed                   \n",
      "0                            0  \n",
      "1                        49464  \n",
      "Accuracy (a decision tree): 0.8458\n",
      "Decision Tree Performance\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.85      0.92      9974\n",
      "          1       0.02      0.96      0.03        26\n",
      "\n",
      "avg / total       1.00      0.85      0.91     10000\n",
      "\n",
      "mean: 0.867 (std: 0.011)\n",
      "\n",
      "Accuracy (a random forest): 0.9199\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96      9974\n",
      "          1       0.03      0.96      0.06        26\n",
      "\n",
      "avg / total       1.00      0.92      0.96     10000\n",
      "\n",
      "Accuracy (adaboost with decision trees): 0.9224\n"
     ]
    }
   ],
   "source": [
    "# resampling - train with a new data set - 50% is_attributed = 1\n",
    "\n",
    "new_train_sample = pd.read_csv('50%_attributed_train.csv')\n",
    "\n",
    "print(new_train_sample.groupby('is_attributed').count())\n",
    "\n",
    "# time processing\n",
    "# create time attributes from the time stamp\n",
    "\n",
    "new_train_sample['click_time'] = pd.to_datetime(new_train_sample['click_time'])\n",
    "new_train_sample['click_date'] = new_train_sample['click_time'].dt.date\n",
    "new_train_sample['click_day'] = new_train_sample['click_time'].dt.weekday\n",
    "new_train_sample['click_hour'] = new_train_sample['click_time'].dt.hour\n",
    "new_train_sample['click_minute'] = new_train_sample['click_time'].dt.minute\n",
    "\n",
    "# Convert the features in to a single np array for faster processing\n",
    "\n",
    "ip = list(new_train_sample['ip'])\n",
    "app = list(new_train_sample['app'])\n",
    "device = list(new_train_sample['device'])\n",
    "os = list(new_train_sample['os'])\n",
    "channel = list(new_train_sample['channel'])\n",
    "click_hour = list(new_train_sample['click_hour'])\n",
    "\n",
    "\n",
    "X = []\n",
    "i = 0\n",
    "for x in range(len(new_train_sample)):\n",
    "    # comment out the applicable\n",
    "    X.append([ip[i], app[i], device[i], os[i], channel[i], click_day[i], click_count[i]])\n",
    "    #X.append([ip[i], app[i], device[i], os[i], channel[i], click_hour[i]])\n",
    "    i += 1\n",
    "    \n",
    "Y = new_train_sample.is_attributed\n",
    "\n",
    "# Define new training data set\n",
    "train_data, train_labels = X, Y\n",
    "\n",
    "# Use the same test_data, test_labels\n",
    "#test_data, test_labels = X[90000:], Y[90000:]\n",
    "\n",
    "# DecisionTree\n",
    "\n",
    "dt = DecisionTreeClassifier(criterion=\"entropy\", splitter=\"best\", random_state=0)\n",
    "dt.fit(train_data, train_labels)\n",
    "\n",
    "print('Accuracy (a decision tree):', dt.score(test_data, test_labels))\n",
    "print(\"Decision Tree Performance\")\n",
    "print(classification_report(test_labels, dt.predict(test_data)))\n",
    "\n",
    "\n",
    "\n",
    "scores = cross_val_score(dt, train_data, train_labels, cv=10)\n",
    "print(\"mean: {:.3f} (std: {:.3f})\".format(scores.mean(),\n",
    "                                          scores.std()),\n",
    "                                          end=\"\\n\\n\" )\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=10, max_features=None)\n",
    "rfc.fit(train_data, train_labels)\n",
    "\n",
    "print('Accuracy (a random forest):', rfc.score(test_data, test_labels))\n",
    "print(classification_report(test_labels, rfc.predict(test_data)))\n",
    "\n",
    "\n",
    "abc = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1), n_estimators=100, learning_rate=0.1)\n",
    "abc.fit(train_data, train_labels)\n",
    "print('Accuracy (adaboost with decision trees):', abc.score(test_data, test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Unnamed: 0     ip    app  device     os  channel  click_time  \\\n",
      "is_attributed                                                                 \n",
      "0                   69250  69250  69250   69250  69250    69250       69250   \n",
      "1                   29678  29678  29678   29678  29678    29678       29678   \n",
      "\n",
      "               attributed_time  \n",
      "is_attributed                   \n",
      "0                            0  \n",
      "1                        29678  \n",
      "Accuracy (a decision tree): 0.9042\n",
      "Decision Tree Performance\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.90      0.95      9974\n",
      "          1       0.03      1.00      0.05        26\n",
      "\n",
      "avg / total       1.00      0.90      0.95     10000\n",
      "\n",
      "mean: 0.890 (std: 0.006)\n",
      "\n",
      "Accuracy (a random forest): 0.9539\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.95      0.98      9974\n",
      "          1       0.05      1.00      0.10        26\n",
      "\n",
      "avg / total       1.00      0.95      0.97     10000\n",
      "\n",
      "Accuracy (adaboost with decision trees): 0.9628\n"
     ]
    }
   ],
   "source": [
    "# resampling - train with a new data set - 30% is_attributed = 1\n",
    "\n",
    "new_train_sample = pd.read_csv('30%_attributed_train.csv')\n",
    "\n",
    "print(new_train_sample.groupby('is_attributed').count())\n",
    "\n",
    "# time processing\n",
    "# create time attributes from the time stamp\n",
    "\n",
    "new_train_sample['click_time'] = pd.to_datetime(new_train_sample['click_time'])\n",
    "new_train_sample['click_date'] = new_train_sample['click_time'].dt.date\n",
    "new_train_sample['click_day'] = new_train_sample['click_time'].dt.weekday\n",
    "new_train_sample['click_hour'] = new_train_sample['click_time'].dt.hour\n",
    "new_train_sample['click_minute'] = new_train_sample['click_time'].dt.minute\n",
    "\n",
    "# Convert the features in to a single np array for faster processing\n",
    "\n",
    "ip = list(new_train_sample['ip'])\n",
    "app = list(new_train_sample['app'])\n",
    "device = list(new_train_sample['device'])\n",
    "os = list(new_train_sample['os'])\n",
    "channel = list(new_train_sample['channel'])\n",
    "click_hour = list(new_train_sample['click_hour'])\n",
    "\n",
    "\n",
    "X = []\n",
    "i = 0\n",
    "for x in range(len(new_train_sample)):\n",
    "    # comment out the applicable\n",
    "    X.append([ip[i], app[i], device[i], os[i], channel[i], click_day[i], click_count[i]])\n",
    "    #X.append([ip[i], app[i], device[i], os[i], channel[i], click_hour[i]])\n",
    "    i += 1\n",
    "    \n",
    "Y = new_train_sample.is_attributed\n",
    "\n",
    "# Define new training data set\n",
    "train_data, train_labels = X, Y\n",
    "\n",
    "# Use the same test_data, test_labels\n",
    "#test_data, test_labels = X[90000:], Y[90000:]\n",
    "\n",
    "# DecisionTree\n",
    "\n",
    "dt = DecisionTreeClassifier(criterion=\"entropy\", splitter=\"best\", random_state=0)\n",
    "dt.fit(train_data, train_labels)\n",
    "\n",
    "print('Accuracy (a decision tree):', dt.score(test_data, test_labels))\n",
    "print(\"Decision Tree Performance\")\n",
    "print(classification_report(test_labels, dt.predict(test_data)))\n",
    "\n",
    "\n",
    "\n",
    "scores = cross_val_score(dt, train_data, train_labels, cv=10)\n",
    "print(\"mean: {:.3f} (std: {:.3f})\".format(scores.mean(),\n",
    "                                          scores.std()),\n",
    "                                          end=\"\\n\\n\" )\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=10, max_features=None)\n",
    "rfc.fit(train_data, train_labels)\n",
    "\n",
    "print('Accuracy (a random forest):', rfc.score(test_data, test_labels))\n",
    "print(classification_report(test_labels, rfc.predict(test_data)))\n",
    "\n",
    "\n",
    "abc = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1), n_estimators=100, learning_rate=0.1)\n",
    "abc.fit(train_data, train_labels)\n",
    "print('Accuracy (adaboost with decision trees):', abc.score(test_data, test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Unnamed: 0     ip    app  device     os  channel  click_time  \\\n",
      "is_attributed                                                                 \n",
      "0                   89035  89035  89035   89035  89035    89035       89035   \n",
      "1                    9893   9893   9893    9893   9893     9893        9893   \n",
      "\n",
      "               attributed_time  \n",
      "is_attributed                   \n",
      "0                            0  \n",
      "1                         9893  \n",
      "Accuracy (a decision tree): 0.9601\n",
      "Decision Tree Performance\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.96      0.98      9974\n",
      "          1       0.05      0.85      0.10        26\n",
      "\n",
      "avg / total       1.00      0.96      0.98     10000\n",
      "\n",
      "mean: 0.947 (std: 0.002)\n",
      "\n",
      "Accuracy (a random forest): 0.9789\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.98      0.99      9974\n",
      "          1       0.10      0.88      0.18        26\n",
      "\n",
      "avg / total       1.00      0.98      0.99     10000\n",
      "\n",
      "Accuracy (adaboost with decision trees): 0.988\n"
     ]
    }
   ],
   "source": [
    "# resampling - train with a new data set - 10% is_attributed = 1\n",
    "\n",
    "new_train_sample = pd.read_csv('10%_attributed_train.csv')\n",
    "\n",
    "print(new_train_sample.groupby('is_attributed').count())\n",
    "\n",
    "# time processing\n",
    "# create time attributes from the time stamp\n",
    "\n",
    "new_train_sample['click_time'] = pd.to_datetime(new_train_sample['click_time'])\n",
    "new_train_sample['click_date'] = new_train_sample['click_time'].dt.date\n",
    "new_train_sample['click_day'] = new_train_sample['click_time'].dt.weekday\n",
    "new_train_sample['click_hour'] = new_train_sample['click_time'].dt.hour\n",
    "new_train_sample['click_minute'] = new_train_sample['click_time'].dt.minute\n",
    "\n",
    "# Convert the features in to a single np array for faster processing\n",
    "\n",
    "ip = list(new_train_sample['ip'])\n",
    "app = list(new_train_sample['app'])\n",
    "device = list(new_train_sample['device'])\n",
    "os = list(new_train_sample['os'])\n",
    "channel = list(new_train_sample['channel'])\n",
    "click_hour = list(new_train_sample['click_hour'])\n",
    "\n",
    "\n",
    "X = []\n",
    "i = 0\n",
    "for x in range(len(new_train_sample)):\n",
    "    # comment out the applicable\n",
    "    X.append([ip[i], app[i], device[i], os[i], channel[i], click_day[i], click_count[i]])\n",
    "    #X.append([ip[i], app[i], device[i], os[i], channel[i], click_hour[i]])\n",
    "    i += 1\n",
    "    \n",
    "Y = new_train_sample.is_attributed\n",
    "\n",
    "# Define new training data set\n",
    "train_data, train_labels = X, Y\n",
    "\n",
    "# Use the same test_data, test_labels\n",
    "#test_data, test_labels = X[90000:], Y[90000:]\n",
    "\n",
    "# DecisionTree\n",
    "\n",
    "dt = DecisionTreeClassifier(criterion=\"entropy\", splitter=\"best\", random_state=0)\n",
    "dt.fit(train_data, train_labels)\n",
    "\n",
    "print('Accuracy (a decision tree):', dt.score(test_data, test_labels))\n",
    "print(\"Decision Tree Performance\")\n",
    "print(classification_report(test_labels, dt.predict(test_data)))\n",
    "\n",
    "\n",
    "\n",
    "scores = cross_val_score(dt, train_data, train_labels, cv=10)\n",
    "print(\"mean: {:.3f} (std: {:.3f})\".format(scores.mean(),\n",
    "                                          scores.std()),\n",
    "                                          end=\"\\n\\n\" )\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=10, max_features=None)\n",
    "rfc.fit(train_data, train_labels)\n",
    "\n",
    "print('Accuracy (a random forest):', rfc.score(test_data, test_labels))\n",
    "print(classification_report(test_labels, rfc.predict(test_data)))\n",
    "\n",
    "\n",
    "abc = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1), n_estimators=100, learning_rate=0.1)\n",
    "abc.fit(train_data, train_labels)\n",
    "print('Accuracy (adaboost with decision trees):', abc.score(test_data, test_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engingeering - Adding Dummy variables for top IP addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:4: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5348, 5314, 73487, 73516, 53454]\n"
     ]
    }
   ],
   "source": [
    "# check the top 5 most common IP\n",
    "\n",
    "df_top_freq = train_sample.groupby(['ip'])['click_time'].agg(\n",
    "    {\"code_count\": len}).sort_values(\n",
    "    \"code_count\", ascending=False).head(5).reset_index()\n",
    "\n",
    "top5_ip = list(df_top_freq['ip'])\n",
    "print(top5_ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 8)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Redeining X, Y\n",
    "\n",
    "is_5348 = [1 if x == 5348 else 0 for x in list(train_sample['ip'])]\n",
    "is_5314 = [1 if x == 5314 else 0 for x in list(train_sample['ip'])]\n",
    "is_73487 = [1 if x == 73487 else 0 for x in list(train_sample['ip'])]\n",
    "is_73516 = [1 if x == 73516 else 0 for x in list(train_sample['ip'])]\n",
    "is_53454 = [1 if x == 53454 else 0 for x in list(train_sample['ip'])]\n",
    "not_a_frequent_ip = [1 if x not in top5_ip else 0 for x in list(train_sample['ip'])]\n",
    "\n",
    "ip = list(train_sample['ip'])\n",
    "app = list(train_sample['app'])\n",
    "device = list(train_sample['device'])\n",
    "os = list(train_sample['os'])\n",
    "channel = list(train_sample['channel'])\n",
    "\n",
    "X = []\n",
    "i = 0\n",
    "\n",
    "for x in range(100000):\n",
    "    # comment out the applicable\n",
    "    X.append([is_5348[i], is_5314[i], is_73487[i], is_73516[i], is_53454[i], not_a_frequent_ip[i], \n",
    "              app[i], device[i], os[i], channel[i], click_day[i], click_count[i]])\n",
    "    #X.append([ip[i], app[i], device[i], os[i], channel[i], click_hour[i]])\n",
    "    i += 1\n",
    "    \n",
    "\n",
    "Y = train_sample.is_attributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (a decision tree): 0.9609\n",
      "Decision Tree Performance\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.96      0.98      9974\n",
      "          1       0.05      0.81      0.10        26\n",
      "\n",
      "avg / total       1.00      0.96      0.98     10000\n",
      "\n",
      "mean: 0.950 (std: 0.002)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DecisionTree\n",
    "\n",
    "dt = DecisionTreeClassifier(criterion=\"entropy\", splitter=\"best\", random_state=0)\n",
    "dt.fit(train_data, train_labels)\n",
    "\n",
    "print('Accuracy (a decision tree):', dt.score(test_data, test_labels))\n",
    "print(\"Decision Tree Performance\")\n",
    "print(classification_report(test_labels, dt.predict(test_data)))\n",
    "\n",
    "\n",
    "\n",
    "scores = cross_val_score(dt, train_data, train_labels, cv=10)\n",
    "print(\"mean: {:.3f} (std: {:.3f})\".format(scores.mean(),\n",
    "                                          scores.std()),\n",
    "                                          end=\"\\n\\n\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (a random forest): 0.9803\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.98      0.99      9974\n",
      "          1       0.10      0.85      0.18        26\n",
      "\n",
      "avg / total       1.00      0.98      0.99     10000\n",
      "\n",
      "Accuracy (adaboost with decision trees): 0.988\n"
     ]
    }
   ],
   "source": [
    "#Ensemble Methods\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=10, max_features=None)\n",
    "rfc.fit(train_data, train_labels)\n",
    "print('Accuracy (a random forest):', rfc.score(test_data, test_labels))\n",
    "print(classification_report(test_labels, rfc.predict(test_data)))\n",
    "\n",
    "abc = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1), n_estimators=100, learning_rate=0.1)\n",
    "abc.fit(train_data, train_labels)\n",
    "print('Accuracy (adaboost with decision trees):', abc.score(test_data, test_labels))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
